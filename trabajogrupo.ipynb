{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Algoritmo de Detección de Coches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"py\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"py\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install opencv-python\n",
    "!py -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Trabajo**\n",
    "\n",
    "1. A\n",
    "2. grandes que el ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Visualizamos el vídeo\n",
    "import cv2\n",
    "\n",
    "# Abrir el archivo de vídeo\n",
    "cap = cv2.VideoCapture(\"trafico.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Mostrar el fotograma en una ventana\n",
    "    cv2.imshow(\"Reproducción\", frame)\n",
    "\n",
    "    # Espera 25 ms; si se pulsa 'q', sale del bucle\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Promedio de Imágenes de trafico y trafico 2**\n",
    "\n",
    "1. A\n",
    "2. grandes que el ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Promediamos las imágenes\n",
    "video = cv2.VideoCapture(\"trafico.mp4\")\n",
    "# Variables para acumular frames\n",
    "accumulated_frame = None\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break  # Fin del video\n",
    "\n",
    "    # Convierte el frame a float32 para acumulación\n",
    "    frame_float = frame.astype(np.float32)\n",
    "\n",
    "    if accumulated_frame is None:\n",
    "        accumulated_frame = frame_float\n",
    "    else:\n",
    "        accumulated_frame += frame_float\n",
    "    frame_count += 1\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Calcula el promedio\n",
    "background = accumulated_frame / frame_count\n",
    "\n",
    "# Convierte de nuevo a uint8 para mostrar/guardar\n",
    "background_uint8 = cv2.convertScaleAbs(background)\n",
    "\n",
    "# Muestra el fondo promedio\n",
    "cv2.imshow('Fondo Promedio', background_uint8)\n",
    "cv2.imwrite('carretera_promedio.jpg', background_uint8)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Promediamos las imágenes\n",
    "video = cv2.VideoCapture(\"trafico2.mp4\")\n",
    "# Variables para acumular frames\n",
    "accumulated_frame = None\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break  # Fin del video\n",
    "\n",
    "    # Convierte el frame a float32 para acumulación\n",
    "    frame_float = frame.astype(np.float32)\n",
    "\n",
    "    if accumulated_frame is None:\n",
    "        accumulated_frame = frame_float\n",
    "    else:\n",
    "        accumulated_frame += frame_float\n",
    "    frame_count += 1\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Calcula el promedio\n",
    "background = accumulated_frame / frame_count\n",
    "\n",
    "# Convierte de nuevo a uint8 para mostrar/guardar\n",
    "background_uint8 = cv2.convertScaleAbs(background)\n",
    "\n",
    "# Muestra el fondo promedio\n",
    "cv2.imshow('Fondo Promedio', background_uint8)\n",
    "cv2.imwrite('carretera_promedio2.jpg', background_uint8)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Vídeo con Blobs**\n",
    "\n",
    "1. Tanto para trafico como para trafico2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMBRALIZACIÓN Y BINARIZACIÓN DEL VIDEO\n",
    "\n",
    "fondo = cv2.imread(\"carretera_promedio.jpg\") #Leer la imagen del fondo.\n",
    "fondo_BW = cv2.cvtColor(fondo, cv2.COLOR_BGR2GRAY) #Pasar el fondo a blanco y negro.\n",
    "\n",
    "video = cv2.VideoCapture(\"trafico.mp4\")\n",
    "frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir el frame a escala de grises\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Restar el fondo al frame actual (diferencia absoluta)\n",
    "    diff = cv2.absdiff(frame_gray, fondo_BW)\n",
    "\n",
    "    # Aplicar un umbral para detectar movimiento (valores mayores a 30, por ejemplo)\n",
    "    T = 50\n",
    "    _, thresh = cv2.threshold(diff, T, 255, cv2.THRESH_BINARY)\n",
    "    #cv2.imshow('Diferencia Absoluta', diff)\n",
    "    #cv2.imshow('Movimiento Detectado', thresh)\n",
    "\n",
    "# DETECCIÓN DE BLOBS EN EL VIDEO    \n",
    "\n",
    "    # Limpiar ruido con operaciones morfológicas\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_DILATE, kernel)\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < 300:\n",
    "            continue  # Ignoramos áreas pequeñas\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # Adaptar área mínima en función de la posición vertical (y)\n",
    "        y_center = y + h // 2\n",
    "        vertical_factor = y_center / frame_height\n",
    "        min_area = 300 + (1 - vertical_factor) * 1500  # dinámico: 300 a 1800\n",
    "\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Resultado\n",
    "    cv2.imshow('Deteccion de Coches', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- RUTAS y PARÁMETROS ----------\n",
    "VIDEO_PATH = \"trafico.mp4\"\n",
    "FONDO_PATH = \"carretera_promedio.jpg\"\n",
    "\n",
    "THRESH = 30\n",
    "MIN_AREA_BASE = 400\n",
    "MIN_AREA_TOP = 1200\n",
    "KERNEL_SIZE = (5, 5)\n",
    "MASK_TIMESTAMP = True\n",
    "\n",
    "TS_Y1, TS_Y2 = -120, -64\n",
    "TS_X1, TS_X2 = -311, -221\n",
    "\n",
    "# Calibración simple px->m (reemplaza por medidas reales)\n",
    "KNOWN_DISTANCE_M = 7\n",
    "CAL_P1 = (1113, 843)\n",
    "CAL_P2 = (1199, 762)\n",
    "\n",
    "# Tracker params\n",
    "MAX_DISAPPEAR = 10\n",
    "MAX_DISTANCE = 130\n",
    "PERSPECTIVE_FACTOR = 2   # >0 aumenta la variación de px/m con la Y; probar 0.5-1.2\n",
    "SPEED_AVG_WINDOW = 100      # usamos 100 frames para promediar velocidades\n",
    "\n",
    "# ---------- CARGA y PREPARACIÓN ----------\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(f\"No se pudo abrir el vídeo '{VIDEO_PATH}'\")\n",
    "\n",
    "frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) if cap.get(cv2.CAP_PROP_FPS) > 0 else 25.0\n",
    "\n",
    "# máscara del timestamp (en píxeles absolutos)\n",
    "def resolve_coord(v, limit): return v if v >= 0 else limit + v\n",
    "ts_y1 = resolve_coord(TS_Y1, frame_h); ts_y2 = resolve_coord(TS_Y2, frame_h)\n",
    "ts_x1 = resolve_coord(TS_X1, frame_w); ts_x2 = resolve_coord(TS_X2, frame_w)\n",
    "mask_full = np.ones((frame_h, frame_w), dtype=np.uint8) * 255\n",
    "if MASK_TIMESTAMP:\n",
    "    mask_full[ts_y1:ts_y2, ts_x1:ts_x2] = 0\n",
    "ts_rect = (ts_x1, ts_y1, ts_x2 - ts_x1, ts_y2 - ts_y1)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, KERNEL_SIZE)\n",
    "\n",
    "fondo = cv2.imread(FONDO_PATH, cv2.IMREAD_GRAYSCALE)\n",
    "if fondo is None:\n",
    "    raise SystemExit(f\"No se pudo leer el fondo '{FONDO_PATH}'\")\n",
    "if fondo.shape != (frame_h, frame_w):\n",
    "    fondo = cv2.resize(fondo, (frame_w, frame_h), interpolation=cv2.INTER_AREA)\n",
    "fondo_masked = cv2.bitwise_and(fondo, fondo, mask=mask_full)\n",
    "\n",
    "# escala px->m\n",
    "cal_dist_px = np.hypot(CAL_P2[0]-CAL_P1[0], CAL_P2[1]-CAL_P1[1])\n",
    "if cal_dist_px <= 0:\n",
    "    raise SystemExit(\"Error calibración: puntos iguales\")\n",
    "PIXELS_PER_METER = cal_dist_px / KNOWN_DISTANCE_M\n",
    "\n",
    "def pixels_per_meter_at(y_center, frame_h=frame_h):\n",
    "    \"\"\"\n",
    "    Devuelve px/m estimados en función de la coordenada vertical del objeto.\n",
    "    La idea: objetos más bajos en la imagen (y grande) están más cerca => más px por metro.\n",
    "    Ajustar PERSPECTIVE_FACTOR según la cámara.\n",
    "    \"\"\"\n",
    "    # normalizar y en [0,1] (0 = top, 1 = bottom)\n",
    "    yn = float(y_center) / float(frame_h)\n",
    "    # factor de corrección centrado en 1.0\n",
    "    corr = 1.0 + PERSPECTIVE_FACTOR * (yn - 0.5) * 2.0\n",
    "    # limitar corr para evitar valores numéricos extremos\n",
    "    corr = max(0.3, min(corr, 3.0))\n",
    "    return PIXELS_PER_METER * corr\n",
    "\n",
    "# ---------- ESTADO DEL TRACKER (persistente) ----------\n",
    "next_object_id = 0\n",
    "objects = {}          # id -> centroid\n",
    "disappeared = {}      # id -> frames missing\n",
    "tracks = {}           # id -> deque of (frame_idx, centroid)\n",
    "frame_index = 0\n",
    "\n",
    "def centroid_from_box(box):\n",
    "    x, y, w, h = box\n",
    "    return (int(x + w/2), int(y + h/2))\n",
    "\n",
    "def euclidean(a, b):\n",
    "    return np.hypot(a[0]-b[0], a[1]-b[1])\n",
    "\n",
    "def register_object(centroid):\n",
    "    global next_object_id\n",
    "    objects[next_object_id] = centroid\n",
    "    disappeared[next_object_id] = 0\n",
    "    tracks[next_object_id] = deque(maxlen=50)\n",
    "    tracks[next_object_id].append((frame_index, centroid))\n",
    "    next_object_id += 1\n",
    "\n",
    "def deregister_object(obj_id):\n",
    "    objects.pop(obj_id, None)\n",
    "    disappeared.pop(obj_id, None)\n",
    "    tracks.pop(obj_id, None)\n",
    "\n",
    "def update_tracker(detections_centroids):\n",
    "    # asociación simple por distancia (voraz), suficiente y rápida para tráfico poco denso\n",
    "    if len(detections_centroids) == 0:\n",
    "        for oid in list(disappeared.keys()):\n",
    "            disappeared[oid] += 1\n",
    "            if disappeared[oid] > MAX_DISAPPEAR:\n",
    "                deregister_object(oid)\n",
    "        return\n",
    "\n",
    "    if len(objects) == 0:\n",
    "        for c in detections_centroids: register_object(c); return\n",
    "\n",
    "    obj_ids = list(objects.keys())\n",
    "    obj_centroids = [objects[i] for i in obj_ids]\n",
    "\n",
    "    D = np.zeros((len(obj_centroids), len(detections_centroids)))\n",
    "    for i, oc in enumerate(obj_centroids):\n",
    "        for j, dc in enumerate(detections_centroids):\n",
    "            D[i, j] = euclidean(oc, dc)\n",
    "\n",
    "    rows = D.min(axis=1).argsort()\n",
    "    cols = D.argmin(axis=1)[rows]\n",
    "    used_rows, used_cols = set(), set()\n",
    "\n",
    "    for r, c in zip(rows, cols):\n",
    "        if r in used_rows or c in used_cols: continue\n",
    "        if D[r, c] > MAX_DISTANCE: continue\n",
    "        oid = obj_ids[r]\n",
    "        objects[oid] = detections_centroids[c]\n",
    "        disappeared[oid] = 0\n",
    "        tracks[oid].append((frame_index, detections_centroids[c]))\n",
    "        used_rows.add(r); used_cols.add(c)\n",
    "\n",
    "    for j in range(len(detections_centroids)):\n",
    "        if j not in used_cols: register_object(detections_centroids[j])\n",
    "\n",
    "    for i in range(len(obj_centroids)):\n",
    "        if i not in used_rows:\n",
    "            oid = obj_ids[i]\n",
    "            disappeared[oid] += 1\n",
    "            if disappeared[oid] > MAX_DISAPPEAR: deregister_object(oid)\n",
    "\n",
    "def compute_speed_for_track(track_deque):\n",
    "    pts = list(track_deque)[-SPEED_AVG_WINDOW:]\n",
    "    if len(pts) < 2:\n",
    "        return None\n",
    "\n",
    "    # sumar desplazamientos segmentales en píxeles y convertir por segmento con su escala local\n",
    "    total_m = 0.0\n",
    "    total_secs = 0.0\n",
    "    for k in range(1, len(pts)):\n",
    "        f0, c0 = pts[k-1]\n",
    "        f1, c1 = pts[k]\n",
    "        df = f1 - f0\n",
    "        if df <= 0:\n",
    "            continue\n",
    "        dp_px = euclidean(c0, c1)\n",
    "        # usar y promedio del segmento para estimar px->m local\n",
    "        y_avg = (c0[1] + c1[1]) / 2.0\n",
    "        pxpm = pixels_per_meter_at(y_avg)\n",
    "        dp_m = dp_px / pxpm\n",
    "        secs = df / float(FPS)\n",
    "        total_m += dp_m\n",
    "        total_secs += secs\n",
    "\n",
    "    if total_secs <= 0 or total_m <= 0:\n",
    "        return None\n",
    "\n",
    "    speed_kmh = (total_m / total_secs) * 3.6\n",
    "    return speed_kmh\n",
    "\n",
    "def rect_intersection_area(a, b):\n",
    "    ax, ay, aw, ah = a; bx, by, bw, bh = b\n",
    "    ix1, iy1 = max(ax, bx), max(ay, by)\n",
    "    ix2, iy2 = min(ax+aw, bx+bw), min(ay+ah, by+bh)\n",
    "    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)\n",
    "    return iw*ih\n",
    "\n",
    "def nms_boxes(boxes, iou_thresh=0.4):\n",
    "    if not boxes: return []\n",
    "    boxes = sorted(boxes, key=lambda b: b[2]*b[3], reverse=True)\n",
    "    keep = []\n",
    "    def iou(a,b):\n",
    "        x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n",
    "        x2 = min(a[0]+a[2], b[0]+b[2]); y2 = min(a[1]+a[3], b[1]+b[3])\n",
    "        w = max(0, x2-x1); h = max(0, y2-y1)\n",
    "        inter = w*h\n",
    "        union = a[2]*a[3] + b[2]*b[3] - inter\n",
    "        return inter/union if union>0 else 0\n",
    "    for b in boxes:\n",
    "        if all(iou(b, k) <= iou_thresh for k in keep):\n",
    "            keep.append(b)\n",
    "    return keep\n",
    "\n",
    "# ---------- BUCLE PRINCIPAL ----------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    gray_masked = cv2.bitwise_and(gray, gray, mask=mask_full)\n",
    "    diff = cv2.absdiff(gray_masked, fondo_masked)\n",
    "    _, thresh = cv2.threshold(diff, THRESH, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    cleaned = cv2.dilate(closed, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detecciones = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < MIN_AREA_BASE: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # ignorar si intersecta fuertemente con timestamp\n",
    "        inter = rect_intersection_area((x,y,w,h), ts_rect)\n",
    "        if inter > 0 and (inter / float(w*h)) > 0.15: continue\n",
    "\n",
    "        # área mínima dinámica según perspectiva\n",
    "        y_center = y + h//2\n",
    "        vertical_factor = y_center / frame_h\n",
    "        min_area = MIN_AREA_BASE + (1 - vertical_factor) * (MIN_AREA_TOP - MIN_AREA_BASE)\n",
    "        if area < min_area: continue\n",
    "\n",
    "        # caso simple: cajas pequeñas -> añadir tal cual\n",
    "        if area < 2 * min_area or w < 80:\n",
    "            detecciones.append((x,y,w,h)); continue\n",
    "\n",
    "        # para blobs grandes: intentar segmentar\n",
    "        roi = cleaned[y:y+h, x:x+w].copy()\n",
    "        roi = cv2.morphologyEx(roi, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(roi, connectivity=8)\n",
    "        roi_filtered = np.zeros_like(roi)\n",
    "        for i in range(1, num_labels):\n",
    "            a = stats[i, cv2.CC_STAT_AREA]\n",
    "            if a >= max(80, 0.01 * area): roi_filtered[labels==i] = 255\n",
    "\n",
    "        ccnts, _ = cv2.findContours(roi_filtered, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(ccnts) <= 1:\n",
    "            detecciones.append((x,y,w,h)); continue\n",
    "\n",
    "        dist = cv2.distanceTransform(roi_filtered, cv2.DIST_L2, 5)\n",
    "        _, sure_fg = cv2.threshold(dist, 0.2 * dist.max(), 255, 0)\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "        unknown = cv2.subtract(roi_filtered, sure_fg)\n",
    "        num_markers, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers = markers + 1\n",
    "        markers[unknown==255] = 0\n",
    "        roi_color = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.watershed(roi_color, markers)\n",
    "\n",
    "        for m in range(2, num_markers+1):\n",
    "            mask_m = np.uint8(markers == m) * 255\n",
    "            cnts_m, _ = cv2.findContours(mask_m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for c_m in cnts_m:\n",
    "                a_m = cv2.contourArea(c_m)\n",
    "                if a_m < 80: continue\n",
    "                x2, y2, w2, h2 = cv2.boundingRect(c_m)\n",
    "                detecciones.append((x + x2, y + y2, w2, h2))\n",
    "\n",
    "    # NMS y filtrado final\n",
    "    final_boxes = nms_boxes(detecciones, iou_thresh=0.4)\n",
    "\n",
    "    # tracker update\n",
    "    detections_centroids = [centroid_from_box(b) for b in final_boxes]\n",
    "    update_tracker(detections_centroids)\n",
    "\n",
    "    # DIBUJAR: sólo velocidad (si disponible) y bbox\n",
    "    for (x, y, w, h) in final_boxes:\n",
    "        aspect = w / float(h + 1e-6)\n",
    "        if aspect < 0.25 or aspect > 4.5 or h < 12: continue\n",
    "\n",
    "        c = centroid_from_box((x,y,w,h))\n",
    "        assigned_id = None; min_d = 1e9\n",
    "        for oid, cent in objects.items():\n",
    "            d = euclidean(c, cent)\n",
    "            if d < min_d and d < MAX_DISTANCE:\n",
    "                min_d = d; assigned_id = oid\n",
    "\n",
    "        color = (0,255,0)\n",
    "\n",
    "        label = \"\"\n",
    "        if assigned_id is not None:\n",
    "            speed = compute_speed_for_track(tracks[assigned_id])\n",
    "            if speed is not None:\n",
    "                label = f\"{int(round(speed))} km/h\"\n",
    "\n",
    "        if speed is not None:\n",
    "            if speed <= 120:\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2)\n",
    "\n",
    "        if label:\n",
    "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            text_x = x + max(0, (w - text_w)//2)\n",
    "            text_y = y - 8\n",
    "            cv2.rectangle(frame, (text_x - 4, text_y - text_h - 4), (text_x + text_w + 4, text_y + 4), (0,0,0), -1)\n",
    "            cv2.putText(frame, label, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # info y calibración visual\n",
    "    cv2.putText(frame, f\"Scale: {PIXELS_PER_METER:.1f} px/m FPS:{FPS:.1f}\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255),1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    frame_index += 1\n",
    "    if cv2.waitKey(25) & 0xFF == ord(\"q\"): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
