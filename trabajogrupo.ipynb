{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Algoritmo de Detección de Coches - Adrián Rodríguez Pérez y Víctor Díaz Puga**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"py\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"py\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install opencv-python\n",
    "!py -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Visualización del Vídeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Visualizamos el vídeo\n",
    "import cv2\n",
    "\n",
    "# Abrir el archivo de vídeo\n",
    "cap = cv2.VideoCapture(\"trafico.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Mostrar el fotograma en una ventana\n",
    "    cv2.imshow(\"Reproducción\", frame)\n",
    "\n",
    "    # Espera 25 ms; si se pulsa 'q', sale del bucle\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Promediado de Imagen del Vídeo \"trafico.mp4\"**\n",
    "\n",
    "Ejecutamos todo el vídeo a tiempo real para procesar cada frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promediamos las imágenes\n",
    "cap = cv2.VideoCapture(\"trafico.mp4\")\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Variables para acumular frames\n",
    "accumulated_frame = None\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Fin del video\n",
    "\n",
    "    # Convierte el frame a float32 para acumulación\n",
    "    frame_float = frame.astype(np.float32)\n",
    "\n",
    "    if accumulated_frame is None:\n",
    "        accumulated_frame = frame_float\n",
    "    else:\n",
    "        accumulated_frame += frame_float\n",
    "    frame_count += 1\n",
    "\n",
    "# Calcula el promedio\n",
    "background = accumulated_frame / frame_count\n",
    "\n",
    "# Convierte de nuevo a uint8 para mostrar/guardar\n",
    "background_uint8 = cv2.convertScaleAbs(background)\n",
    "\n",
    "cv2.imwrite('carretera_promedio.jpg', background_uint8)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### **Vídeo Procesado**\n",
    "\n",
    "Detectamos cada coche del vídeo y obtenemos su velocidad y le proporcionamos un id a cada uno, el algoritmo se divide en:\n",
    " - **Rutas y Parámetros**: En esta sección guardamos el vídeo y la imagen promedio que usaremos para detectar el movimiento, además estableceremos todas las constantes que usaremos más tarde\n",
    " - **Carga y Preparación**: Obtendremos las variables que dependen del vídeo como el tamaño del mismo o su relación entre píxeles y metros, también definimos la máscara para eliminar el movimiento del temporizador\n",
    " - **Estado del Tracker**: Definimos todas las funciones que usaremos después en el bucle para obtener la posición, la velocidad y el seguimiento de los coches con sus ids asociados\n",
    " - **Bucle Principal**: Procesa cada frame del vídeo para analizar el movimiento, hace todos los cálculos necesarios para dibujar el contador de coches, dónde se encuentra cada uno, su respectivo id y a la velocidad a la que se desplaza en el mismo vídeo y mostrarlo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de Uso con \"trafico.mp4\"\n",
    "# ---------- RUTAS y PARÁMETROS ----------\n",
    "VIDEO_PATH = \"trafico.mp4\"\n",
    "FONDO_PATH = \"carretera_promedio.jpg\"\n",
    "\n",
    "THRESH = 30  # umbral binarización\n",
    "MIN_AREA_BASE = 400  # base\n",
    "MIN_AREA_TOP = 1200  # altura\n",
    "KERNEL_SIZE = (5, 5)\n",
    "\n",
    "TS_Y1, TS_Y2 = -120, -64\n",
    "TS_X1, TS_X2 = -311, -221\n",
    "\n",
    "# Calibración simple px->m (reemplaza por medidas reales)\n",
    "KNOWN_DISTANCE_M = 7\n",
    "CAL_P1 = (1113, 843)\n",
    "CAL_P2 = (1199, 762)\n",
    "\n",
    "# Tracker params\n",
    "MAX_DISAPPEAR = 15  # frames antes de borrar objeto\n",
    "MAX_DISTANCE = 200  # distancia máxima para considerar que sigue siendo el mismo objeto\n",
    "PERSPECTIVE_FACTOR = 2  # ajusta la variación de px/m con la altura\n",
    "SPEED_AVG_WINDOW = 100  # usamos 100 frames para promediar velocidades\n",
    "DIST_THRESHOLD = 90  # píxeles de distancia máxima para fusionar\n",
    "\n",
    "# ---------- CARGA y PREPARACIÓN ----------\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(f\"No se pudo abrir el vídeo '{VIDEO_PATH}'\")\n",
    "\n",
    "frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # obtenemos la anchura del vídeo\n",
    "frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # obtenemos la altura del vídeo\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) if cap.get(cv2.CAP_PROP_FPS) > 0 else 25.0  # fps del vídeo\n",
    "\n",
    "# máscara del timestamp (en píxeles absolutos)\n",
    "def resolve_coord(v, limit): return v if v >= 0 else limit + v\n",
    "ts_y1 = resolve_coord(TS_Y1, frame_h); ts_y2 = resolve_coord(TS_Y2, frame_h)\n",
    "ts_x1 = resolve_coord(TS_X1, frame_w); ts_x2 = resolve_coord(TS_X2, frame_w)\n",
    "mask_full = np.ones((frame_h, frame_w), dtype=np.uint8) * 255\n",
    "\n",
    "# aplicar máscara timestamp\n",
    "if True:  # la desactivaríamos para vídeos sin cronómetro\n",
    "    mask_full[ts_y1:ts_y2, ts_x1:ts_x2] = 0  # pone a 0 la parte del cronómetro de la imagen binaria\n",
    "ts_rect = (ts_x1, ts_y1, ts_x2 - ts_x1, ts_y2 - ts_y1)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, KERNEL_SIZE)\n",
    "\n",
    "fondo = cv2.imread(FONDO_PATH, cv2.IMREAD_GRAYSCALE)  # escala de grises\n",
    "fondo_masked = cv2.bitwise_and(fondo, fondo, mask=mask_full)  # aplicar máscara de tiempo al fondo\n",
    "\n",
    "# escala px->m\n",
    "cal_dist_px = np.hypot(CAL_P2[0]-CAL_P1[0], CAL_P2[1]-CAL_P1[1])\n",
    "PIXELS_PER_METER = cal_dist_px / KNOWN_DISTANCE_M  # calculamos los píxeles por metro\n",
    "\n",
    "def pixels_per_meter_at(y_center, frame_h=frame_h):\n",
    "    \"\"\"\n",
    "    Devuelve px/m estimados en función de la altura del objeto en el vídeo\n",
    "    Los objetos más bajos en la imagen están más cerca, más px por metro\n",
    "    \"\"\"\n",
    "    # normalizar y en [0,1] (0 = arriba, 1 = abajo)\n",
    "    yn = float(y_center) / float(frame_h)\n",
    "    # factor de corrección centrado en 1.0\n",
    "    corr = 1 + PERSPECTIVE_FACTOR * (yn - 0.5) * 2\n",
    "    # limitar corr para evitar velocidades extremos\n",
    "    corr = max(0.3, min(corr, 3))  # factor entre 0.3 y 3\n",
    "    return PIXELS_PER_METER * corr\n",
    "\n",
    "# ---------- ESTADO DEL TRACKER (persistente) ----------\n",
    "next_object_id = 0\n",
    "objects = {}  # id -> posición central del coche\n",
    "disappeared = {}  # id -> número de frames consecutivos en los que ese id no se detectó\n",
    "tracks = {}  # id -> historial de posiciones (frame_index, posición)\n",
    "frame_index = 0  # contador global de frames\n",
    "\n",
    "def centroid_from_box(box):\n",
    "    x, y, w, h = box  # x e y son la esquina superior izquierda, w y h el ancho y alto\n",
    "    return (int(x + w/2), int(y + h/2))  # centro del blob (suma para bajar y mover a la derecha)\n",
    "\n",
    "def euclidean(a, b):\n",
    "    return np.hypot(a[0]-b[0], a[1]-b[1])  # distancia entre 2 puntos\n",
    "\n",
    "# registrar nuevo objeto en el tracker\n",
    "def register_object(centroid):\n",
    "    global next_object_id\n",
    "    objects[next_object_id] = centroid\n",
    "    disappeared[next_object_id] = 0\n",
    "    tracks[next_object_id] = deque(maxlen=50)  # genera la tupla\n",
    "    tracks[next_object_id].append((frame_index, centroid))\n",
    "    next_object_id += 1\n",
    "\n",
    "# eliminar objeto del tracker\n",
    "def deregister_object(obj_id):  # le pasamos el id del objeto a eliminar\n",
    "    objects.pop(obj_id, None)\n",
    "    disappeared.pop(obj_id, None)\n",
    "    tracks.pop(obj_id, None)\n",
    "\n",
    "# actualizar el tracker con nuevas detecciones\n",
    "def update_tracker(detections_centroids):  # le pasamos la lista de centroides detectados en el frame actual\n",
    "    if len(detections_centroids) == 0:  # si no hay detecciones en el frame actual, aumentamos el contador de desaparecidos a todos\n",
    "        for oid in list(disappeared.keys()):\n",
    "            disappeared[oid] += 1\n",
    "            if disappeared[oid] > MAX_DISAPPEAR:\n",
    "                deregister_object(oid)  # eliminar objeto\n",
    "        return\n",
    "\n",
    "    if len(objects) == 0:\n",
    "        for c in detections_centroids: register_object(c); return  # registrar todos los coches cuando no hay ninguno\n",
    "\n",
    "    obj_ids = list(objects.keys())  # lista de ids de vehículos actuales\n",
    "    obj_centroids = [objects[i] for i in obj_ids]  # lista de centroides actuales\n",
    "\n",
    "    D = np.zeros((len(obj_centroids), len(detections_centroids)))  # matriz de distancias (objetos existente x detecciones nuevas)\n",
    "    for i, oc in enumerate(obj_centroids):\n",
    "        for j, dc in enumerate(detections_centroids):\n",
    "            D[i, j] = euclidean(oc, dc)\n",
    "\n",
    "    rows = D.min(axis=1).argsort()\n",
    "    cols = D.argmin(axis=1)[rows]\n",
    "    used_rows, used_cols = set(), set()\n",
    "\n",
    "    for r, c in zip(rows, cols):\n",
    "        if r in used_rows or c in used_cols: continue\n",
    "        if D[r, c] > MAX_DISTANCE: continue  # si la distancia es muy grande, no es el mismo objeto\n",
    "        oid = obj_ids[r]  # nueva detección para el mejor futuro cadidato del objeto existente\n",
    "        objects[oid] = detections_centroids[c]\n",
    "        disappeared[oid] = 0\n",
    "        tracks[oid].append((frame_index, detections_centroids[c]))\n",
    "        used_rows.add(r); used_cols.add(c)\n",
    "\n",
    "    for j in range(len(detections_centroids)):\n",
    "        if j not in used_cols: register_object(detections_centroids[j])  # registra nuevas detecciones que no coinciden con objetos existentes\n",
    "\n",
    "    for i in range(len(obj_centroids)):  # si hay ids de objetos existentes que no se han actualizado, aumenta su contador de desaparecido\n",
    "        if i not in used_rows:\n",
    "            oid = obj_ids[i]\n",
    "            disappeared[oid] += 1\n",
    "            if disappeared[oid] > MAX_DISAPPEAR: deregister_object(oid)\n",
    "\n",
    "# calcular velocidad promedio para un track\n",
    "def compute_speed_for_track(track_deque):\n",
    "    pts = list(track_deque)[-SPEED_AVG_WINDOW:]\n",
    "    if len(pts) < 2:\n",
    "        return None\n",
    "\n",
    "    # sumar desplazamientos segmentales en píxeles y convertir por segmento con su escala local\n",
    "    total_m = 0.0\n",
    "    total_secs = 0.0\n",
    "    for k in range(1, len(pts)):\n",
    "        f0, c0 = pts[k-1]\n",
    "        f1, c1 = pts[k]\n",
    "        df = f1 - f0\n",
    "        if df <= 0:\n",
    "            continue\n",
    "        dp_px = euclidean(c0, c1)\n",
    "        # usar y promedio del segmento para estimar px->m local\n",
    "        y_avg = (c0[1] + c1[1]) / 2.0\n",
    "        pxpm = pixels_per_meter_at(y_avg)\n",
    "        dp_m = dp_px / pxpm\n",
    "        secs = df / float(FPS)\n",
    "        total_m += dp_m\n",
    "        total_secs += secs\n",
    "\n",
    "    if total_secs <= 0 or total_m <= 0:\n",
    "        return None\n",
    "\n",
    "    speed_kmh = (total_m / total_secs) * 3.6\n",
    "    return speed_kmh\n",
    "\n",
    "def rect_intersection_area(a, b):\n",
    "    ax, ay, aw, ah = a; bx, by, bw, bh = b\n",
    "    ix1, iy1 = max(ax, bx), max(ay, by)\n",
    "    ix2, iy2 = min(ax+aw, bx+bw), min(ay+ah, by+bh)\n",
    "    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)\n",
    "    return iw*ih\n",
    "\n",
    "def nms_boxes(boxes, iou_thresh):  # devuelve lista de cajas que no se superponen\n",
    "    if not boxes: return []\n",
    "    boxes = sorted(boxes, key=lambda b: b[2]*b[3], reverse=True)\n",
    "    keep = []\n",
    "    def iou(a,b):  # te dice si está muy superpuesto el objeto entre 0 y 1\n",
    "        x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n",
    "        x2 = min(a[0]+a[2], b[0]+b[2]); y2 = min(a[1]+a[3], b[1]+b[3])\n",
    "        w = max(0, x2-x1); h = max(0, y2-y1)\n",
    "        inter = w*h\n",
    "        union = a[2]*a[3] + b[2]*b[3] - inter\n",
    "        return inter/union if union>0 else 0\n",
    "    for b in boxes:\n",
    "        if all(iou(b, k) <= iou_thresh for k in keep):\n",
    "            keep.append(b)\n",
    "    return keep\n",
    "\n",
    "def fuse_close_centroids(detections_centroids):\n",
    "    fused_centroids = []\n",
    "    used = set()\n",
    "\n",
    "    for i, c1 in enumerate(detections_centroids):\n",
    "        if i in used:\n",
    "            continue\n",
    "        grupo = [c1]\n",
    "        for j, c2 in enumerate(detections_centroids):\n",
    "            if j <= i or j in used:\n",
    "                continue\n",
    "            dx = c1[0] - c2[0]\n",
    "            dy = c1[1] - c2[1]\n",
    "            dist = (dx**2 + dy**2)**0.5\n",
    "            if dist < DIST_THRESHOLD:\n",
    "                grupo.append(c2)\n",
    "                used.add(j)\n",
    "        # Promediamos el grupo de centroides cercanos\n",
    "        if len(grupo) > 1:\n",
    "            avg_x = sum(c[0] for c in grupo) / len(grupo)\n",
    "            avg_y = sum(c[1] for c in grupo) / len(grupo)\n",
    "            fused_centroids.append((int(avg_x), int(avg_y)))\n",
    "        else:\n",
    "            fused_centroids.append(c1)\n",
    "    return fused_centroids\n",
    "\n",
    "# ---------- BUCLE PRINCIPAL ----------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    gray_masked = cv2.bitwise_and(gray, gray, mask=mask_full)\n",
    "    diff = cv2.absdiff(gray_masked, fondo_masked)\n",
    "    _, thresh = cv2.threshold(diff, THRESH, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    cleaned = cv2.dilate(closed, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detecciones = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < MIN_AREA_BASE: continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # ignorar si intersecta fuertemente con timestamp\n",
    "        inter = rect_intersection_area((x,y,w,h), ts_rect)\n",
    "        if inter > 0 and (inter / float(w*h)) > 0.15: continue\n",
    "\n",
    "        # área mínima dinámica según perspectiva\n",
    "        y_center = y + h//2\n",
    "        vertical_factor = y_center / frame_h\n",
    "        min_area = MIN_AREA_BASE + (1 - vertical_factor) * (MIN_AREA_TOP - MIN_AREA_BASE)\n",
    "        if area < min_area: continue\n",
    "\n",
    "        # caso simple: cajas pequeñas -> añadir tal cual\n",
    "        if area < 2 * min_area or w < 80:\n",
    "            detecciones.append((x,y,w,h)); continue\n",
    "\n",
    "        # para blobs grandes: intentar segmentar\n",
    "        roi = cleaned[y:y+h, x:x+w].copy()\n",
    "        roi = cv2.morphologyEx(roi, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(roi, connectivity=8)\n",
    "        roi_filtered = np.zeros_like(roi)\n",
    "        for i in range(1, num_labels):\n",
    "            a = stats[i, cv2.CC_STAT_AREA]\n",
    "            if a >= max(80, 0.01 * area): roi_filtered[labels==i] = 255\n",
    "\n",
    "        ccnts, _ = cv2.findContours(roi_filtered, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(ccnts) <= 1:\n",
    "            detecciones.append((x,y,w,h)); continue\n",
    "\n",
    "        dist = cv2.distanceTransform(roi_filtered, cv2.DIST_L2, 5)\n",
    "        _, sure_fg = cv2.threshold(dist, 0.2 * dist.max(), 255, 0)\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "        unknown = cv2.subtract(roi_filtered, sure_fg)\n",
    "        num_markers, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers = markers + 1\n",
    "        markers[unknown==255] = 0\n",
    "        roi_color = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.watershed(roi_color, markers)\n",
    "\n",
    "        for m in range(2, num_markers+1):\n",
    "            mask_m = np.uint8(markers == m) * 255\n",
    "            cnts_m, _ = cv2.findContours(mask_m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for c_m in cnts_m:\n",
    "                a_m = cv2.contourArea(c_m)\n",
    "                if a_m < 80: continue\n",
    "                x2, y2, w2, h2 = cv2.boundingRect(c_m)\n",
    "                detecciones.append((x + x2, y + y2, w2, h2))\n",
    "\n",
    "    # NMS y filtrado final\n",
    "    final_boxes = nms_boxes(detecciones, iou_thresh=0)\n",
    "\n",
    "    # tracker update\n",
    "    detections_centroids = [centroid_from_box(b) for b in final_boxes]\n",
    "\n",
    "    # Fusión de centroides muy cercanos\n",
    "    detections_centroids = fuse_close_centroids(detections_centroids)\n",
    "    \n",
    "    update_tracker(detections_centroids)\n",
    "\n",
    "    # DIBUJAR: sólo velocidad (si disponible) y bbox\n",
    "    for (x, y, w, h) in final_boxes:\n",
    "        aspect = w / float(h + 1e-6)\n",
    "        if aspect < 0.25 or aspect > 4.5 or h < 12: continue\n",
    "\n",
    "        c = centroid_from_box((x,y,w,h))\n",
    "        assigned_id = None; min_d = 1e9\n",
    "        for oid, cent in objects.items():\n",
    "            d = euclidean(c, cent)\n",
    "            if d < min_d and d < MAX_DISTANCE:\n",
    "                min_d = d; assigned_id = oid\n",
    "\n",
    "        color = (0,255,0)\n",
    "\n",
    "        label = \"\"\n",
    "        if assigned_id is not None:\n",
    "            speed = compute_speed_for_track(tracks[assigned_id])\n",
    "            if speed is not None:\n",
    "                label = f\"{int(round(speed))} km/h, ID:{assigned_id}\"\n",
    "\n",
    "        if speed is not None:\n",
    "            if speed <= 120:\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2)\n",
    "\n",
    "        if label:\n",
    "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            text_x = x + max(0, (w - text_w)//2)\n",
    "            text_y = y - 8\n",
    "            cv2.rectangle(frame, (text_x - 4, text_y - text_h - 4), (text_x + text_w + 4, text_y + 4), (0,0,0), -1)\n",
    "            cv2.putText(frame, label, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # info y calibración visual\n",
    "    cv2.putText(frame, f\"Scale: {PIXELS_PER_METER:.1f}px/m, FPS: {FPS:.0f}, Num Coches: {next_object_id}\", (140,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (117, 38, 40), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    frame_index += 1\n",
    "    if cv2.waitKey(25) & 0xFF == ord(\"q\"): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
